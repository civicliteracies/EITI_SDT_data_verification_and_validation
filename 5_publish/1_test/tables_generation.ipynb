{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/k9wh63yn4bzb0fzdgjkcx6tw0000gn/T/ipykernel_5017/947216789.py:5: DtypeWarning: Columns (5,8,12,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_part5 = pd.read_csv(url_part5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url_part1=('https://raw.githubusercontent.com/civicliteracies/EITI_SDT_data_verification_and_validation/sqlite/4_clean/2_data_editing/output/eiti-data_part1_1.3.csv')\n",
    "url_part5=('https://raw.githubusercontent.com/civicliteracies/EITI_SDT_data_verification_and_validation/sqlite/4_clean/2_data_editing/output/eiti-data_part5-0.11.8.csv')\n",
    "\n",
    "df_part1 = pd.read_csv(url_part1)\n",
    "df_part5 = pd.read_csv(url_part5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Generating statements\n",
    "\n",
    "1. Starting from the consolidated part 1 of the summary data file, we perform an initial mapping of the dataset columns to the relevant fields of the [BODS 0.4 schema](https://github.com/openownership/data-standard/tree/main/schema, using \n",
    "    * a [mapping reference](https://docs.google.com/spreadsheets/d/1CPeZ_5FiqIRCmHGHh7Gz1McpxmwN1EoBwkMYtRqFWFo/edit?pli=1#gid=134387124) made possible by [flattening the BODS json schema](https://github.com/civicliteracies/EITI_SDT_data_verification_and_validation/blob/sqlite/4_clean/3_bods_mapping/02_schema_flattening.ipynb) files\n",
    "    * a dictionary modelled after the BODS statemement schema.\n",
    "    * a loop that processes the Part 1's data using the instructions in the mapping reference.\n",
    "2. We store the created JSON statements in a dictionary using the statemeent IDs as keys to facilitate matching with the future JSON files containing recordDetails info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dictionnary has73\n",
      "0d9c43a6-f72e-398b-b1eb-771b510ea6eb: {\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": \"n/v\",\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2017-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-21\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Maher Kabsi\",\n",
      "        \"uri\": \"Maher.Kabsi@bdo-ifi.com\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"CG-20170101-20171231\",\n",
      "  \"declarationSubject\": \"CG\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {}\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "935a9737-16b1-316e-8c3e-9a12c3c27470: {\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": \"2021-03-31\",\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2018-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-21\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Rached Maalej\",\n",
      "        \"uri\": \"rached.maalej@bdo-ifi.com\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"GY-20180101-20181231\",\n",
      "  \"declarationSubject\": \"GY\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {}\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BODS statement structure template\n",
    "bods_statement_schema = {\n",
    "    \"statementId\": \"\",\n",
    "    \"statementDate\": \"\",\n",
    "    \"annotations\": [],\n",
    "    \"publicationDetails\": {\n",
    "        \"publicationDate\": \"\",\n",
    "        \"bodsVersion\": \"\",\n",
    "        \"license\": \"\",\n",
    "        \"publisher\": {\n",
    "            \"name\": \"\",\n",
    "            \"url\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"source\": {\n",
    "        \"type\": [],\n",
    "        \"description\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"retrievedAt\": \"\",\n",
    "        \"assertedBy\": [\n",
    "            {\n",
    "                \"name\": \"\",\n",
    "                \"uri\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"declaration\": \"\",\n",
    "    \"declarationSubject\": \"\",\n",
    "    \"recordId\": \"\",\n",
    "    \"recordType\": \"\",\n",
    "    \"recordDetails\": {}\n",
    "}\n",
    "\n",
    "# Dictionary to hold the JSON strings\n",
    "statement_dict = {}\n",
    "\n",
    "# Iterate over each row in df_part1\n",
    "for index, row in df_part1.iterrows():\n",
    "    bods_statement = bods_statement_schema.copy()\n",
    "\n",
    "    # Fill the bods_statement with data from the row\n",
    "    bods_statement[\"statementId\"] = ''\n",
    "    bods_statement[\"statementDate\"] = row['eiti_data_publication_date']\n",
    "    bods_statement[\"publicationDetails\"][\"publicationDate\"] = row['end_date']\n",
    "    bods_statement[\"publicationDetails\"][\"bodsVersion\"] = '0.4'\n",
    "    bods_statement[\"publicationDetails\"][\"license\"] = 'http://opendatacommons.org/licenses/pddl/1.0/'\n",
    "    bods_statement[\"publicationDetails\"][\"publisher\"][\"name\"] = 'Extractive Industries Transparency Initiative'\n",
    "    bods_statement[\"publicationDetails\"][\"publisher\"][\"url\"] = 'https://eiti.org/open-data'\n",
    "    bods_statement[\"source\"][\"type\"] = ['officialRegister', 'verified']\n",
    "    bods_statement[\"source\"][\"url\"] = 'https://eiti.portaljs.com'\n",
    "    bods_statement[\"source\"][\"retrievedAt\"] = pd.Timestamp('today').strftime('%Y-%m-%d')\n",
    "    bods_statement[\"source\"][\"assertedBy\"][0][\"name\"] = row['submitter_name']\n",
    "    bods_statement[\"source\"][\"assertedBy\"][0][\"uri\"] = row['submitter_email']\n",
    "    bods_statement[\"declaration\"] = f\"{row['iso_alpha2_code']}-{row['start_date'].replace('-', '')}-{row['end_date'].replace('-', '')}\"\n",
    "    bods_statement[\"declarationSubject\"] = row['iso_alpha2_code']\n",
    "    bods_statement[\"recordId\"] = ''\n",
    "    bods_statement[\"recordType\"] = ''\n",
    "    \n",
    "    # Create a variable name based on the statement identifier\n",
    "    variable_name = row['eiti_id_declaration']\n",
    "    \n",
    "    # Save the JSON string in the dictionary\n",
    "    statement_dict[variable_name] = json.dumps(bods_statement, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Print a sample of 2 random iterms froom the dictionary containing JSON strings\n",
    "separator = \"-\" * 40\n",
    "random_keys = random.sample(list(statement_dict.keys()), 2)\n",
    "\n",
    "print(f\"the dictionnary has {len(statement_dict.keys())} \")\n",
    "\n",
    "for random_key in random_keys:\n",
    "    print(f\"{random_key}: {statement_dict[random_key]}\\n{separator}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Generating Entities\n",
    "\n",
    "TODO: \n",
    "1. need to change back the dictionary construction to generate one json per recordDetails\n",
    "2. There is one statement per record details. Does it mean that I have to match then duplicate the statements for each recordDetails?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique entities and add entity type\n",
    "unique_companies = df_part5[['company_name', 'eiti_id_company', 'iso_alpha2_code', 'country', 'company_public_listing_or_website', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_company']).drop_duplicates().assign(entity_type='registeredEntity')\n",
    "unique_projects = df_part5[['project_name', 'eiti_id_project', 'iso_alpha2_code', 'country', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_project']).drop_duplicates().assign(entity_type='arrangement')\n",
    "unique_government = df_part5[['government_entity', 'eiti_id_government', 'iso_alpha2_code', 'country', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_government']).drop_duplicates().assign(entity_type='stateBody')\n",
    "\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_combined = pd.concat([unique_companies, unique_projects, unique_government], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. 8242 rows processed.\n",
      "\n",
      "f11d93c6-1ca8-3b49-b082-f4bd12e7c5cb: {\n",
      "  \"isComponent\": false,\n",
      "  \"entityType\": {\n",
      "    \"type\": \"stateBody\",\n",
      "    \"subtype\": \"stateAgency\",\n",
      "    \"details\": \"\"\n",
      "  },\n",
      "  \"name\": \"SOCIÉTÉ DES HYDROCARBURES DU TCHAD (SHT)\",\n",
      "  \"jurisdiction\": {\n",
      "    \"name\": \"Chad\",\n",
      "    \"code\": \"TD\"\n",
      "  },\n",
      "  \"identifiers\": [\n",
      "    {\n",
      "      \"id\": \"2789c7a9-d3c3-4c03-85bc-9101eecf9a7a\",\n",
      "      \"scheme\": \"XI-EITI\",\n",
      "      \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"uri\": \"/entity_statement/2789c7a9-d3c3-4c03-85bc-9101eecf9a7a\"\n",
      "    }\n",
      "  ],\n",
      "  \"addresses\": [],\n",
      "  \"uri\": NaN,\n",
      "  \"publicListing\": null,\n",
      "  \"formedByStatute\": null\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "32ec6b11-e012-3080-919e-e5ba08c0d92f: {\n",
      "  \"isComponent\": false,\n",
      "  \"entityType\": {\n",
      "    \"type\": \"stateBody\",\n",
      "    \"subtype\": \"stateAgency\",\n",
      "    \"details\": \"\"\n",
      "  },\n",
      "  \"name\": \"ETHIOPIAN REVENUES AND CUSTOMS AUTHORITY (ERCA)\",\n",
      "  \"jurisdiction\": {\n",
      "    \"name\": \"Ethiopia\",\n",
      "    \"code\": \"ET\"\n",
      "  },\n",
      "  \"identifiers\": [\n",
      "    {\n",
      "      \"id\": \"89036dfd-fed3-4a44-8e26-05999ffa8a7c\",\n",
      "      \"scheme\": \"XI-EITI\",\n",
      "      \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"uri\": \"/entity_statement/89036dfd-fed3-4a44-8e26-05999ffa8a7c\"\n",
      "    }\n",
      "  ],\n",
      "  \"addresses\": [],\n",
      "  \"uri\": NaN,\n",
      "  \"publicListing\": null,\n",
      "  \"formedByStatute\": null\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the BODS entity structure based on the JSON schema\n",
    "bods_entity_schema = {\n",
    "    \"isComponent\": False,\n",
    "    \"entityType\": {\n",
    "        \"type\": \"\",\n",
    "        \"subtype\": \"\",\n",
    "        \"details\": \"\"\n",
    "    },\n",
    "    \"name\": \"\",\n",
    "    \"jurisdiction\": {\n",
    "        \"name\": \"\",\n",
    "        \"code\": \"\"\n",
    "    },\n",
    "    \"identifiers\": [],\n",
    "    \"addresses\": [],\n",
    "    \"uri\": \"\",\n",
    "    \"publicListing\": None,\n",
    "    \"formedByStatute\": None\n",
    "}\n",
    "\n",
    "# Create a dictionary to hold the JSON files using declaration_reference as the key\n",
    "entity_dict = {}\n",
    "\n",
    "# Iterate over each row in df_combined to create JSON files\n",
    "for index, row in df_combined.iterrows():\n",
    "    if index % 100 == 0:  # Update progress every 100 rows\n",
    "        print(f\"\\rProcessing row {index+1}/{len(df_combined)}\", end='')\n",
    "\n",
    "    bods_entity = bods_entity_schema.copy()\n",
    "\n",
    "    bods_entity[\"isComponent\"] = False\n",
    "    bods_entity[\"entityType\"][\"type\"] = row['entity_type']\n",
    "    bods_entity[\"entityType\"][\"subtype\"] = (\n",
    "        'governmentDepartment' if row['entity_type'] == 'stateBody' and 'minist' in str(row['government_entity']).lower() else\n",
    "        'stateAgency' if row['entity_type'] == 'stateBody' else ''\n",
    "    )\n",
    "    bods_entity[\"name\"] = (\n",
    "        row['company_name'] if row['entity_type'] == 'registeredEntity' else\n",
    "        row['project_name'] if row['entity_type'] == 'arrangement' else\n",
    "        row['government_entity']\n",
    "    )\n",
    "    bods_entity[\"jurisdiction\"][\"name\"] = row['country']\n",
    "    bods_entity[\"jurisdiction\"][\"code\"] = row['iso_alpha2_code']\n",
    "    bods_entity[\"identifiers\"] = [{\n",
    "        \"id\": (\n",
    "            row['eiti_id_company'] if row['entity_type'] == 'registeredEntity' else\n",
    "            row['eiti_id_project'] if row['entity_type'] == 'arrangement' else\n",
    "            row['eiti_id_government']\n",
    "        ),\n",
    "        \"scheme\": \"XI-EITI\",\n",
    "        \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
    "        \"uri\": f\"/entity_statement/{row['eiti_id_company'] if row['entity_type'] == 'registeredEntity' else row['eiti_id_project'] if row['entity_type'] == 'arrangement' else row['eiti_id_government']}\"\n",
    "    }]\n",
    "    bods_entity[\"uri\"] = row['company_public_listing_or_website']\n",
    "    \n",
    "    # Create a variable name based on the statement identifier\n",
    "    variable_name = row['eiti_id_declaration']\n",
    "\n",
    "    # Add the JSON string to the dictionary with the declaration_reference as the key\n",
    "    entity_dict[variable_name] = json.dumps(bods_entity, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Ensure the progress line is cleared after completion\n",
    "print(f\"\\rProcessing completed. {len(df_combined)} rows processed.\\n\")\n",
    "\n",
    "\n",
    "random_keys = random.sample(list(entity_dict.keys()), 2)\n",
    "\n",
    "for random_key in random_keys:\n",
    "    print(f\"{random_key}: {entity_dict[random_key]}\\n{separator}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found for key: 1f61bd83-c1cd-3658-8fab-29ba86d584a7\n",
      "Match found for key: c40776d5-a273-3f9d-b805-075e804b9f3e\n",
      "Match found for key: fb121867-d9c5-3112-90f5-f798ed67c49d\n",
      "Match found for key: e821dd0c-7660-3334-a55a-732ab12351d7\n",
      "Match found for key: 2df5c073-4216-3f74-a2cd-23aa44dd3c9c\n",
      "Match found for key: 4c603c65-856f-307e-9317-a0aafd609fd9\n",
      "Match found for key: 3feda957-7e06-3973-b6b9-4516a8d00747\n",
      "Match found for key: e29c05ee-d532-38fa-a930-6f5e20b1767c\n",
      "Match found for key: d060e8fb-01b0-3ff5-9c5a-76d13e6b2eb1\n",
      "Match found for key: 1b63ccc9-6e10-38f3-893b-b4acc6621a33\n",
      "Match found for key: bca8d920-8812-3357-938f-429117baa1c5\n",
      "Match found for key: 116e309f-4a0e-3322-bb55-48bce11e119c\n",
      "Match found for key: 71c9f815-7b52-3ee6-b348-4d6fce4857e5\n",
      "Match found for key: 386f455d-e70c-3e0f-a9e4-2177c6c841ef\n",
      "Match found for key: ccfb08b7-f235-3638-9b1e-b2627cc5d1d9\n",
      "Match found for key: 0d9c43a6-f72e-398b-b1eb-771b510ea6eb\n",
      "Match found for key: 3db323c5-52f0-3d2a-a301-18a90f9e9bad\n",
      "Match found for key: e0b5e228-58db-3de0-b7e0-1a9ce15f64bb\n",
      "Match found for key: 6802fa65-6c70-333b-bf14-5c89d9cd400d\n",
      "Match found for key: 3dd0e5ac-530d-3cb4-9bfd-6e9a3f0b2b91\n",
      "Match found for key: 7229dcbd-2847-3895-a2ee-9732a8d98744\n",
      "Match found for key: b00c9e86-069e-3cba-9c71-ec6c1d8acc2f\n",
      "Match found for key: 4718e6f9-6259-3876-86a7-42060858205b\n",
      "Match found for key: 32ec6b11-e012-3080-919e-e5ba08c0d92f\n",
      "Match found for key: ffba0b4e-e211-3ba8-9df9-fc6f919281a4\n",
      "Match found for key: 1fec5e66-7e78-3028-81d7-8d97e3348ded\n",
      "Match found for key: 25618157-0b01-392a-a758-583b79ad3c0e\n",
      "Match found for key: 2ec5844e-1937-3172-bf7a-e4fb8430a9c4\n",
      "Match found for key: 9984e501-79e0-3630-9afd-1dc278c5a715\n",
      "Match found for key: b25269d3-7e8d-365a-8156-e0dc1b542d54\n",
      "Match found for key: 5b4d53c5-2d0f-3c87-b71e-06e4505d459f\n",
      "Match found for key: 935a9737-16b1-316e-8c3e-9a12c3c27470\n",
      "Match found for key: bc9d63a5-5dde-3d88-9777-15aa4895b0a9\n",
      "Match found for key: b576d457-908b-3fbe-aa03-4a7b07c69d9a\n",
      "Match found for key: 4e63c3eb-2fcd-3149-8811-1691d82162ec\n",
      "Match found for key: 822e6097-313c-32d0-9ca4-4db85c24052d\n",
      "Match found for key: 4b7f7a40-3d50-38a2-8504-9760458d523a\n",
      "Match found for key: 3bd1e8e1-9463-35f7-bfe4-c1e40177d578\n",
      "Match found for key: bde10cb7-34f9-3d15-8e13-65b1899ba250\n",
      "Match found for key: e7853b05-d03e-3848-93ec-d21f6cdf39ea\n",
      "Match found for key: ca6733b9-5ad6-3305-afde-3db9c19fcf3c\n",
      "Match found for key: 919aa363-4086-3318-8c0d-69fc2c399736\n",
      "Match found for key: d0e555e6-734d-3cc8-9d0d-5ff29d0aca24\n",
      "Match found for key: 64d735a9-88f0-3265-a0b5-d539d8537144\n",
      "Match found for key: 4ea01700-862a-30f5-92f7-e5b1431b3f69\n",
      "Match found for key: 092597d9-697f-3dc1-8b54-8493c8f2afce\n",
      "Match found for key: e5e7c542-e52b-3dda-adad-8cd101ea7fdb\n",
      "Match found for key: 34c68921-5795-302a-a802-db7e9ef1cf31\n",
      "Match found for key: 4a310016-9552-3539-bc27-fa55ce8f2f49\n",
      "Match found for key: 7d7869d9-aae0-3389-91b6-86c06f873f49\n",
      "Match found for key: 1dd00639-96ac-3312-b687-8c7ffd939bbc\n",
      "Match found for key: 4765534e-a29e-3564-8b53-00b93fb3a490\n",
      "Match found for key: 79ba792a-616e-315e-bda7-53b1561f0187\n",
      "Match found for key: a7b7e710-937b-3798-8255-3b58b3e33c34\n",
      "Match found for key: ae9cff7e-bad2-3f5a-89e6-02681ec75e81\n",
      "Match found for key: ea080e1e-c1d5-3215-b841-8e423f66acd0\n",
      "Match found for key: 4a8b4137-6af1-306b-a321-7c9cab4ad6a7\n",
      "Match found for key: ed7f717c-14b2-3fed-acec-f3082d40eab1\n",
      "Match found for key: bfa84e89-dbd8-3bc8-b038-9a9b3de9e663\n",
      "Match found for key: f11d93c6-1ca8-3b49-b082-f4bd12e7c5cb\n",
      "Match found for key: e7c2170f-97e5-3330-9cdf-3e27e3dc7ca3\n",
      "Match found for key: 13555e5d-3cca-37a7-a9ca-253e35b302f0\n",
      "Match found for key: a03f2e35-d84d-3ea0-a072-49fd69ad77c6\n",
      "Match found for key: ae7276dc-d516-32e7-8e25-f5dcad63b2a5\n",
      "Match found for key: 7c434c19-4f09-36ab-b04b-ee6397be4007\n",
      "Match found for key: 4bc19a64-96ea-33ff-b490-b0bc996e446b\n",
      "Match found for key: 90cc5c63-ce01-3228-a745-7376d043d665\n",
      "Match found for key: 54bec788-8c5c-3c77-af56-09cfcb43830a\n",
      "Match found for key: f1a966c7-d6b9-3cb7-a10a-b9cb0f63a4c7\n",
      "Match found for key: fef32215-a021-3118-bdc3-a44079a72bdd\n",
      "Match found for key: acb80970-c46e-3169-8ba6-d85c21d30aee\n",
      "Match found for key: 10d0408e-ef95-35ca-bb4e-07f9aa1c2979\n",
      "Match found for key: 5abb2996-ea0c-36b0-a728-8e9de6fe4f97\n",
      "Number of combined entries: 73\n",
      "Combined Entry 5:\n",
      "{\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": \"2020-09-14\",\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2018-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-21\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Heghine Ghukasyan\",\n",
      "        \"uri\": \"heghine.ghukasyan@am.ey.com\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"AM-20180101-20181231\",\n",
      "  \"declarationSubject\": \"AM\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {\n",
      "    \"isComponent\": false,\n",
      "    \"entityType\": {\n",
      "      \"type\": \"stateBody\",\n",
      "      \"subtype\": \"governmentDepartment\",\n",
      "      \"details\": \"\"\n",
      "    },\n",
      "    \"name\": \"MINISTRY OF ENVIRONMENT\",\n",
      "    \"jurisdiction\": {\n",
      "      \"name\": \"Armenia\",\n",
      "      \"code\": \"AM\"\n",
      "    },\n",
      "    \"identifiers\": [\n",
      "      {\n",
      "        \"id\": \"4cf9a8f4-66d9-448b-b519-51af3aa5e6f1\",\n",
      "        \"scheme\": \"XI-EITI\",\n",
      "        \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "        \"uri\": \"/entity_statement/4cf9a8f4-66d9-448b-b519-51af3aa5e6f1\"\n",
      "      }\n",
      "    ],\n",
      "    \"addresses\": [],\n",
      "    \"uri\": NaN,\n",
      "    \"publicListing\": null,\n",
      "    \"formedByStatute\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Combined Entry 61:\n",
      "{\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": NaN,\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2017-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-21\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Ahmed Zouari\",\n",
      "        \"uri\": \"Ahmed.zouari@bdo.co.uk\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"TG-20170101-20171231\",\n",
      "  \"declarationSubject\": \"TG\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {\n",
      "    \"isComponent\": false,\n",
      "    \"entityType\": {\n",
      "      \"type\": \"stateBody\",\n",
      "      \"subtype\": \"stateAgency\",\n",
      "      \"details\": \"\"\n",
      "    },\n",
      "    \"name\": \"SOCIETE TOGOLAISE DES EAUX (TDE)\",\n",
      "    \"jurisdiction\": {\n",
      "      \"name\": \"Togo\",\n",
      "      \"code\": \"TG\"\n",
      "    },\n",
      "    \"identifiers\": [\n",
      "      {\n",
      "        \"id\": \"d53a6e41-887a-4d35-a388-84f67f8e9670\",\n",
      "        \"scheme\": \"XI-EITI\",\n",
      "        \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "        \"uri\": \"/entity_statement/d53a6e41-887a-4d35-a388-84f67f8e9670\"\n",
      "      }\n",
      "    ],\n",
      "    \"addresses\": [],\n",
      "    \"uri\": NaN,\n",
      "    \"publicListing\": null,\n",
      "    \"formedByStatute\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_dict = {}\n",
    "index = 0\n",
    "\n",
    "for key in entity_dict.keys():\n",
    "    if key in statement_dict:\n",
    "        print(f\"Match found for key: {key}\")  # Debug message\n",
    "        statement = json.loads(statement_dict[key])\n",
    "        entity = json.loads(entity_dict[key])\n",
    "        statement[\"recordDetails\"] = entity\n",
    "        combined_dict[index] = json.dumps(statement, indent=2, ensure_ascii=False)\n",
    "        index += 1\n",
    "\n",
    "# Print the length of the combined dictionary\n",
    "print(f\"Number of combined entries: {len(combined_dict)}\")\n",
    "\n",
    "# Display only 2 random items\n",
    "if combined_dict:\n",
    "    random_keys = random.sample(list(combined_dict.keys()), min(2, len(combined_dict)))\n",
    "    for key in random_keys:\n",
    "        print(f\"Combined Entry {key}:\")\n",
    "        print(combined_dict[key])\n",
    "        print(\"\\n\\n\")\n",
    "else:\n",
    "    print(\"No matching keys found between statement_dict and entity_dict.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Relationships\n",
    "\n",
    "TODO \n",
    "1. Gnerate the relationship record details\n",
    "2. Need to add a payment details sub-structure in relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Matching statements to declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaration Reference: AF-20171221-20181220 has 1 entities\n",
      "Declaration Reference: AF-20181221-20191220 has 1 entities\n",
      "Declaration Reference: AL-20170101-20171231 has 1 entities\n",
      "Declaration Reference: AL-20180101-20181231 has 1 entities\n",
      "Declaration Reference: AR-20180101-20181231 has 1 entities\n",
      "Declaration Reference: AM-20180101-20181231 has 1 entities\n",
      "Declaration Reference: AM-20190101-20191231 has 1 entities\n",
      "Declaration Reference: BF-20170101-20171231 has 1 entities\n",
      "Declaration Reference: BF-20180101-20181231 has 1 entities\n",
      "Declaration Reference: BF-20190101-20191231 has 1 entities\n",
      "Declaration Reference: BF-20201201-20201231 has 1 entities\n",
      "Declaration Reference: CI-20170101-20171231 has 1 entities\n",
      "Declaration Reference: CI-20180101-20181231 has 1 entities\n",
      "Declaration Reference: CM-20170101-20171231 has 1 entities\n",
      "Declaration Reference: CD-20170101-20171231 has 1 entities\n",
      "Declaration Reference: CG-20170101-20171231 has 1 entities\n",
      "Declaration Reference: DE-20170101-20171231 has 1 entities\n",
      "Declaration Reference: DE-20180101-20181231 has 1 entities\n",
      "Declaration Reference: DE-20190101-20191231 has 1 entities\n",
      "Declaration Reference: DE-20200101-20201231 has 1 entities\n",
      "Declaration Reference: DO-20180101-20181231 has 1 entities\n",
      "Declaration Reference: DO-20190101-20191231 has 1 entities\n",
      "Declaration Reference: DO-20200101-20201231 has 1 entities\n",
      "Declaration Reference: ET-20160708-20170707 has 1 entities\n",
      "Declaration Reference: GB-20180101-20181231 has 1 entities\n",
      "Declaration Reference: GB-20190101-20191231 has 1 entities\n",
      "Declaration Reference: GB-20200101-20201231 has 1 entities\n",
      "Declaration Reference: GH-20170101-20171231 has 1 entities\n",
      "Declaration Reference: GH-20180101-20181231 has 1 entities\n",
      "Declaration Reference: GH-20190101-20191231 has 1 entities\n",
      "Declaration Reference: GT-20170101-20171201 has 1 entities\n",
      "Declaration Reference: GY-20180101-20181231 has 1 entities\n",
      "Declaration Reference: IQ-20170101-20171231 has 1 entities\n",
      "Declaration Reference: IQ-20180101-20181231 has 1 entities\n",
      "Declaration Reference: LR-20170701-20180630 has 1 entities\n",
      "Declaration Reference: LR-20180701-20190630 has 1 entities\n",
      "Declaration Reference: MG-20170101-20171231 has 1 entities\n",
      "Declaration Reference: MG-20180101-20181231 has 1 entities\n",
      "Declaration Reference: MX-20170101-20171231 has 1 entities\n",
      "Declaration Reference: MX-20180101-20181231 has 1 entities\n",
      "Declaration Reference: ML-20170101-20171231 has 1 entities\n",
      "Declaration Reference: ML-20180101-20181231 has 1 entities\n",
      "Declaration Reference: MM-20170401-20180331 has 1 entities\n",
      "Declaration Reference: MN-20180101-20181231 has 1 entities\n",
      "Declaration Reference: MN-20190101-20191231 has 1 entities\n",
      "Declaration Reference: MN-20200101-20201231 has 1 entities\n",
      "Declaration Reference: MZ-20190101-20191231 has 1 entities\n",
      "Declaration Reference: MR-20170101-20171231 has 1 entities\n",
      "Declaration Reference: NG-20170101-20171231 has 1 entities\n",
      "Declaration Reference: NG-20180101-20181231 has 1 entities\n",
      "Declaration Reference: NO-20170101-20171231 has 1 entities\n",
      "Declaration Reference: NO-20180101-20181231 has 1 entities\n",
      "Declaration Reference: NO-20190101-20191231 has 1 entities\n",
      "Declaration Reference: PH-20180101-20181231 has 1 entities\n",
      "Declaration Reference: SN-20180101-20181231 has 1 entities\n",
      "Declaration Reference: SN-20190101-20191231 has 1 entities\n",
      "Declaration Reference: SR-20170101-20171231 has 1 entities\n",
      "Declaration Reference: SC-20170101-20171231 has 1 entities\n",
      "Declaration Reference: SC-20180101-20181231 has 1 entities\n",
      "Declaration Reference: TD-20170101-20171231 has 1 entities\n",
      "Declaration Reference: TD-20180101-20181231 has 1 entities\n",
      "Declaration Reference: TG-20170101-20171231 has 1 entities\n",
      "Declaration Reference: TG-20180101-20181231 has 1 entities\n",
      "Declaration Reference: TT-20161001-20170930 has 1 entities\n",
      "Declaration Reference: TT-20171001-20180930 has 1 entities\n",
      "Declaration Reference: TZ-20170701-20180630 has 1 entities\n",
      "Declaration Reference: UA-20170101-20171231 has 1 entities\n",
      "Declaration Reference: UA-20180101-20181231 has 1 entities\n",
      "Declaration Reference: UA-20190101-20191231 has 1 entities\n",
      "Declaration Reference: UA-20200101-20201231 has 1 entities\n",
      "Declaration Reference: ZM-20170101-20171231 has 1 entities\n",
      "Declaration Reference: ZM-20180101-20181231 has 1 entities\n",
      "Declaration Reference: ZM-20190101-20191231 has 1 entities\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cleaned_entity_dict = {}\n",
    "for declaration_reference, bods_entity_str in entity_dict.items():\n",
    "    cleaned_key = declaration_reference.replace(\"Declaration Reference: \", \"\").strip()\n",
    "    cleaned_entity_dict[cleaned_key] = bods_entity_str\n",
    "\n",
    "# Create a dictionary to group entities by cleaned declaration_reference\n",
    "grouped_entities = defaultdict(list)\n",
    "\n",
    "# Iterate over each entry in cleaned_entity_dict to group entities by declaration_reference\n",
    "for declaration_reference, bods_entity_str in cleaned_entity_dict.items():\n",
    "    bods_entity = json.loads(bods_entity_str)\n",
    "    grouped_entities[declaration_reference].append(bods_entity)\n",
    "\n",
    "# Debug: Print the number of entities for each declaration reference\n",
    "for declaration_reference, entities in grouped_entities.items():\n",
    "    print(f\"Declaration Reference: {declaration_reference} has {len(entities)} entities\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
