{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook describes the mapping process of EITI data to the Beneficial Ownership Data Standard [BODS 0.4](https://github.com/openownership/data-standard/tree/main/schema. It is structured in 5 sections: \n",
    "0. Prerequisites\n",
    "1. Statement Mapping\n",
    "2. Entity Mapping\n",
    "3. Relationship mapping\n",
    "4. Final matching\n",
    "5. Declaration export\n",
    "\n",
    "### Mapping process\n",
    "\n",
    "The mapping sections are broadly structured in 3 parts: \n",
    "1. Schema and dictionary definition\n",
    "2. Mapping function\n",
    "3. Output verification \n",
    "\n",
    "They rely on a [mapping reference](https://docs.google.com/spreadsheets/d/1CPeZ_5FiqIRCmHGHh7Gz1McpxmwN1EoBwkMYtRqFWFo/edit?pli=1#gid=134387124) made possible by [flattening the BODS json schema](https://github.com/civicliteracies/EITI_SDT_data_verification_and_validation/blob/sqlite/4_clean/3_bods_mapping/02_schema_flattening.ipynb) files.\n",
    "\n",
    "The mapping process uses dictionaries to hold the target data structures, and the data is transformed using the following logic: \n",
    "\n",
    "`<bods_object>_schema` serves as a blueprint for the `<bods_object>_json` instances that are populated with data from `df_<dataset>`, assigned a unique identifier `<bods_object>_dict_key`, and stored as JSON strings in the `<bods_object>_dict` dictionary.\n",
    "\n",
    "where `<bods_object>` can be either statement, entity or relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 - Prerequisites\n",
    "\n",
    "### Overview\n",
    "1. Import libraries\n",
    "3. Import the data as dataframes\n",
    "2. Define utility functions and variables to be used across the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "0.1. We import the appropriate libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2. We import the relevant datasets directly from Github to facilitate replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_part1=('https://raw.githubusercontent.com/civicliteracies/EITI_SDT_data_verification_and_validation/sqlite/4_clean/2_data_editing/output/eiti-data_part1_1.3.csv')\n",
    "url_part5=('https://raw.githubusercontent.com/civicliteracies/EITI_SDT_data_verification_and_validation/sqlite/4_clean/2_data_editing/output/eiti-data_part5-0.11.8.csv')\n",
    "\n",
    "df_part1 = pd.read_csv(url_part1)\n",
    "df_part5 = pd.read_csv(url_part5, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3. we define the various utility functions needed for later: \n",
    "* a uuid3 function used to create a recordID for relationship entities\n",
    "* a uuid4 function used to create a statementID for relationship entities\n",
    "* a function to print 2 random items from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate UUID3 based on subject and interestedParty\n",
    "def generate_uuid3(subject, interestedParty):\n",
    "    namespace = uuid.UUID('00000000-0000-0000-0000-000000000000')\n",
    "    name = f\"{subject}-{interestedParty}\"\n",
    "    return str(uuid.uuid3(namespace, name))\n",
    "\n",
    "# Generate UUID4 for statementId\n",
    "def generate_uuid4():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "# Print a sample of 2 random items from the dictionary containing JSON strings\n",
    "def print_random_keys(dictionary, num_keys=2):\n",
    "    separator = \"-\" * 40\n",
    "    random_keys = random.sample(list(dictionary.keys()), num_keys)\n",
    "    \n",
    "    for random_key in random_keys:\n",
    "        print(f\"{random_key}: {dictionary[random_key]}\\n{separator}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Generating statements\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Schema and dictionary definition\n",
    "2. Mapping\n",
    "3. Output verification\n",
    "\n",
    "### Logic\n",
    "\n",
    "`statement_schema` serves as a blueprint for creating `statement_json` instances, which are populated with data from `df_part1`, assigned unique identifiers `statement_dict_key`, and stored as JSON strings in the `statement_dict` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 We define the schema and create the dictionary to hold the mappped JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BODS statement structure template\n",
    "statement_schema = {\n",
    "    \"statementId\": \"\",\n",
    "    \"statementDate\": \"\",\n",
    "    \"annotations\": [],\n",
    "    \"publicationDetails\": {\n",
    "        \"publicationDate\": \"\",\n",
    "        \"bodsVersion\": \"\",\n",
    "        \"license\": \"\",\n",
    "        \"publisher\": {\n",
    "            \"name\": \"\",\n",
    "            \"url\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"source\": {\n",
    "        \"type\": [],\n",
    "        \"description\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"retrievedAt\": \"\",\n",
    "        \"assertedBy\": [\n",
    "            {\n",
    "                \"name\": \"\",\n",
    "                \"uri\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"declaration\": \"\",\n",
    "    \"declarationSubject\": \"\",\n",
    "    \"recordId\": \"\",\n",
    "    \"recordType\": \"\",\n",
    "    \"recordDetails\": {}\n",
    "}\n",
    "\n",
    "# Dictionary to hold the JSON strings\n",
    "statement_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. We loop through part1 data to generate the JSON based on the mapping rules and we print the number of created JSONs for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionnary has 73 items\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate over each row in df_part1\n",
    "for index, row in df_part1.iterrows():\n",
    "    statement_json = statement_schema.copy()\n",
    "\n",
    "    # Fill the statement_json with data from the row\n",
    "    statement_json[\"statementId\"] = ''\n",
    "    statement_json[\"statementDate\"] = row['eiti_data_publication_date']\n",
    "    statement_json[\"publicationDetails\"][\"publicationDate\"] = row['end_date']\n",
    "    statement_json[\"publicationDetails\"][\"bodsVersion\"] = '0.4'\n",
    "    statement_json[\"publicationDetails\"][\"license\"] = 'http://opendatacommons.org/licenses/pddl/1.0/'\n",
    "    statement_json[\"publicationDetails\"][\"publisher\"][\"name\"] = 'Extractive Industries Transparency Initiative'\n",
    "    statement_json[\"publicationDetails\"][\"publisher\"][\"url\"] = 'https://eiti.org/open-data'\n",
    "    statement_json[\"source\"][\"type\"] = ['officialRegister', 'verified']\n",
    "    statement_json[\"source\"][\"url\"] = 'https://eiti.portaljs.com'\n",
    "    statement_json[\"source\"][\"retrievedAt\"] = pd.Timestamp('today').strftime('%Y-%m-%d')\n",
    "    statement_json[\"source\"][\"assertedBy\"][0][\"name\"] = row['submitter_name']\n",
    "    statement_json[\"source\"][\"assertedBy\"][0][\"uri\"] = row['submitter_email']\n",
    "    statement_json[\"declaration\"] = f\"{row['iso_alpha2_code']}-{row['start_date'].replace('-', '')}-{row['end_date'].replace('-', '')}\"\n",
    "    statement_json[\"declarationSubject\"] = row['iso_alpha2_code']\n",
    "    statement_json[\"recordId\"] = ''\n",
    "    statement_json[\"recordType\"] = ''\n",
    "    \n",
    "    # Create a key based on the statement identifier\n",
    "    statement_dict_key = row['eiti_id_declaration']\n",
    "    \n",
    "    # Save the JSON string in the dictionary\n",
    "    statement_dict[statement_dict_key] = json.dumps(statement_json, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"The dictionnary has {len(statement_dict.keys())} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. We verify the output by printing 2 random statement_dict entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4c603c65-856f-307e-9317-a0aafd609fd9: {\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": \"2020-09-14\",\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2018-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-30\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Heghine Ghukasyan\",\n",
      "        \"uri\": \"heghine.ghukasyan@am.ey.com\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"AM-20180101-20181231\",\n",
      "  \"declarationSubject\": \"AM\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {}\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "bfa84e89-dbd8-3bc8-b038-9a9b3de9e663: {\n",
      "  \"statementId\": \"\",\n",
      "  \"statementDate\": \"2019-12-31\",\n",
      "  \"annotations\": [],\n",
      "  \"publicationDetails\": {\n",
      "    \"publicationDate\": \"2018-12-31\",\n",
      "    \"bodsVersion\": \"0.4\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/1.0/\",\n",
      "    \"publisher\": {\n",
      "      \"name\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"url\": \"https://eiti.org/open-data\"\n",
      "    }\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"type\": [\n",
      "      \"officialRegister\",\n",
      "      \"verified\"\n",
      "    ],\n",
      "    \"description\": \"\",\n",
      "    \"url\": \"https://eiti.portaljs.com\",\n",
      "    \"retrievedAt\": \"2024-05-30\",\n",
      "    \"assertedBy\": [\n",
      "      {\n",
      "        \"name\": \"Ms Nadia Jeremie\",\n",
      "        \"uri\": \"nadia.jeremie@src.gov.sc\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"declaration\": \"SC-20180101-20181231\",\n",
      "  \"declarationSubject\": \"SC\",\n",
      "  \"recordId\": \"\",\n",
      "  \"recordType\": \"\",\n",
      "  \"recordDetails\": {}\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_random_keys(statement_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Generating Entities\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Entity data preparation\n",
    "2. Schema and dictionary definition\n",
    "3. Mapping\n",
    "4. Output verification\n",
    "\n",
    "### Logic\n",
    "\n",
    "`entity_schema` serves as a blueprint for creating `entity_json` instances, which are populated with data from `df_part1`, assigned unique identifiers `entity_dict_key`, and stored as JSON strings in the `entity_dict` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. We create a dataframe that holds only the unique values for each type of entity (companies, projects, government entities) while assigning them the proper label in the `entity_type` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 8242 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract unique entities and add entity type\n",
    "unique_companies = df_part5[['company_name', 'eiti_id_company', 'iso_alpha2_code', 'country', 'company_public_listing_or_website', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_company']).drop_duplicates().assign(entity_type='registeredEntity')\n",
    "unique_projects = df_part5[['project_name', 'eiti_id_project', 'iso_alpha2_code', 'country', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_project']).drop_duplicates().assign(entity_type='arrangement')\n",
    "unique_government = df_part5[['government_entity', 'eiti_id_government', 'iso_alpha2_code', 'country', 'start_date', 'end_date', 'eiti_id_declaration']].dropna(subset=['eiti_id_government']).drop_duplicates().assign(entity_type='stateBody')\n",
    "\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_entities = pd.concat([unique_companies, unique_projects, unique_government], ignore_index=True)\n",
    "\n",
    "print(f\"The dataframe has {len(df_entities.index)} rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. We define the schema and create the dictionary to hold the mappped JSONs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entity schema\n",
    "entity_schema = {\n",
    "    \"isComponent\": False,\n",
    "    \"entityType\": {\n",
    "        \"type\": \"\",\n",
    "        \"subtype\": \"\",\n",
    "        \"details\": \"\"\n",
    "    },\n",
    "    \"name\": \"\",\n",
    "    \"jurisdiction\": {\n",
    "        \"name\": \"\",\n",
    "        \"code\": \"\"\n",
    "    },\n",
    "    \"identifiers\": [],\n",
    "    \"addresses\": [],\n",
    "    \"uri\": \"\",\n",
    "    \"publicListing\": None,\n",
    "    \"formedByStatute\": None\n",
    "}\n",
    "\n",
    "# Create the entity dictionary\n",
    "entity_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. We loop through `df_entities` to generate the mapped entity JSONs before stroing them in `entity_dict`.  The size of the `entity_dict` should match the number of rows of `df_entities`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over each row in df_entities to create JSON files\n",
    "for index, row in df_entities.iterrows():\n",
    "\n",
    "    entity_json = entity_schema.copy()\n",
    "\n",
    "    entity_json[\"isComponent\"] = False\n",
    "    entity_json[\"entityType\"][\"type\"] = row['entity_type']\n",
    "    entity_json[\"entityType\"][\"subtype\"] = (\n",
    "        'governmentDepartment' if row['entity_type'] == 'stateBody' and 'minist' in str(row['government_entity']).lower() else\n",
    "        'stateAgency' if row['entity_type'] == 'stateBody' else ''\n",
    "    )\n",
    "    entity_json[\"name\"] = (\n",
    "        row['company_name'] if row['entity_type'] == 'registeredEntity' else\n",
    "        row['project_name'] if row['entity_type'] == 'arrangement' else\n",
    "        row['government_entity']\n",
    "    )\n",
    "    entity_json[\"jurisdiction\"][\"name\"] = row['country']\n",
    "    entity_json[\"jurisdiction\"][\"code\"] = row['iso_alpha2_code']\n",
    "    entity_json[\"identifiers\"] = [{\n",
    "        \"id\": (\n",
    "            row['eiti_id_company'] if row['entity_type'] == 'registeredEntity' else\n",
    "            row['eiti_id_project'] if row['entity_type'] == 'arrangement' else\n",
    "            row['eiti_id_government']\n",
    "        ),\n",
    "        \"scheme\": \"XI-EITI\",\n",
    "        \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
    "        \"uri\": f\"/entity_statement/{row['eiti_id_company'] if row['entity_type'] == 'registeredEntity' else row['eiti_id_project'] if row['entity_type'] == 'arrangement' else row['eiti_id_government']}\"\n",
    "    }]\n",
    "    entity_json[\"uri\"] = row['company_public_listing_or_website']\n",
    "    \n",
    "    # Create the dictionary key\n",
    "    entity_dict_key = (index, row['eiti_id_declaration'])\n",
    "\n",
    "    # Insert entity JSONs in the dictionary alongside their matching keys\n",
    "    entity_dict[entity_dict_key] = json.dumps(entity_json, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Clear process status with a final message\n",
    "print(f\"The dictionnary has {len(entity_dict.keys())} items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. We verify the output by printing 2 random statement_dict entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8128, '4a310016-9552-3539-bc27-fa55ce8f2f49'): {\n",
      "  \"isComponent\": false,\n",
      "  \"entityType\": {\n",
      "    \"type\": \"stateBody\",\n",
      "    \"subtype\": \"stateAgency\",\n",
      "    \"details\": \"\"\n",
      "  },\n",
      "  \"name\": \"NIGER DELTA DEVELOPMENT COMMISSION\",\n",
      "  \"jurisdiction\": {\n",
      "    \"name\": \"Nigeria\",\n",
      "    \"code\": \"NG\"\n",
      "  },\n",
      "  \"identifiers\": [\n",
      "    {\n",
      "      \"id\": \"af5ac417-4623-437b-84e4-692b0ff135bc\",\n",
      "      \"scheme\": \"XI-EITI\",\n",
      "      \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"uri\": \"/entity_statement/af5ac417-4623-437b-84e4-692b0ff135bc\"\n",
      "    }\n",
      "  ],\n",
      "  \"addresses\": [],\n",
      "  \"uri\": NaN,\n",
      "  \"publicListing\": null,\n",
      "  \"formedByStatute\": null\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "(8179, 'e7c2170f-97e5-3330-9cdf-3e27e3dc7ca3'): {\n",
      "  \"isComponent\": false,\n",
      "  \"entityType\": {\n",
      "    \"type\": \"stateBody\",\n",
      "    \"subtype\": \"stateAgency\",\n",
      "    \"details\": \"\"\n",
      "  },\n",
      "  \"name\": \"DIRECTION GÉNÉRALE DU TRÉSOR ET DE LA COMPTABILITÉ PUBLIQUE (DGTCP)\",\n",
      "  \"jurisdiction\": {\n",
      "    \"name\": \"Chad\",\n",
      "    \"code\": \"TD\"\n",
      "  },\n",
      "  \"identifiers\": [\n",
      "    {\n",
      "      \"id\": \"69ee59d1-5acb-4c8e-938b-a1c383773b10\",\n",
      "      \"scheme\": \"XI-EITI\",\n",
      "      \"schemeName\": \"Extractive Industries Transparency Initiative\",\n",
      "      \"uri\": \"/entity_statement/69ee59d1-5acb-4c8e-938b-a1c383773b10\"\n",
      "    }\n",
      "  ],\n",
      "  \"addresses\": [],\n",
      "  \"uri\": NaN,\n",
      "  \"publicListing\": null,\n",
      "  \"formedByStatute\": null\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display 2 random items for quality check\n",
    "print_random_keys(entity_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Relationships\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Schema and dictionary definition\n",
    "2. Mapping to the different relationship schemas\n",
    "3. Output verification\n",
    "4. Consolidation\n",
    "\n",
    "## Logic \n",
    "\n",
    "### Core mapping\n",
    "\n",
    "EITI data describes multiple relationships, requiring the definition of several schemas. We defined 5 types of relationships and assigned the following attributes\n",
    "\n",
    "| InterestedParty | Subject | directOrIndirect | descriptor |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| Country | Government Agency | direct | controlByLegalFramework |\n",
    "| Government Agency | Company (SOE) | direct | controlByLegalFramework, rightsToProfitOrIncome |\n",
    "| Government Agency | Company (Private) | direct | rightsToProfitOrIncome |\n",
    "| Company | Project | direct | rightsGrantedByContract |\n",
    "| Government Agency | Project | indirect | controlByLegalFramework |\n",
    "\n",
    "Those are used in the five different `relationship_schemas`. \n",
    "\n",
    "The `populate_relationships` function uses `relationship_schemas` as a template to create `relationship_json` instances, which are populated with data from the `df_part5`. Each `relationship_json` is then stored as a JSON string in the `relationship_dicts` dictionary under the corresponding `relationship_type` inner dictionary, using a tuple of the row index and `eiti_id_declaration` as the unique key.\n",
    "\n",
    "### Schema extension\n",
    "\n",
    "In the context of EITI data, the interests linking an InterestedParty (government entity/company) to a subject (company, project) refer to the monetary value or in-kind amount of taxes paid to a government entity, whether directly or in relation to a specific project. BODS does not have a specific mechanism to add arbitrary interests, so we added them in interests[].details property by transforming the expected value from a string to an array of objects. This allow us to add the relevant information while minisming the additional nesting level, following BODS design philosophy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. We define the five possible schemas as a single dictionary, as well as five separate dictionaries to hold the JSON files mapped to each schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_schemas = {\n",
    "    \"country_government\": {\n",
    "        \"subject\": \"\",\n",
    "        \"interestedParty\": \"\",\n",
    "        \"interests\": [{\n",
    "            \"type\": \"controlByLegalFramework\",\n",
    "            \"directOrIndirect\": \"direct\",\n",
    "            \"beneficialOwnershipOrControl\": False,\n",
    "        }],\n",
    "        \"isComponent\": False\n",
    "    },\n",
    "    \"government_soe\": {\n",
    "        \"subject\": \"\",\n",
    "        \"interestedParty\": \"\",\n",
    "        \"interests\": [\n",
    "            {\n",
    "                \"type\": \"controlByLegalFramework\",\n",
    "                \"directOrIndirect\": \"direct\",\n",
    "                \"beneficialOwnershipOrControl\": False,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"rightsToProfitOrIncome\",\n",
    "                \"directOrIndirect\": \"direct\",\n",
    "                \"beneficialOwnershipOrControl\": False,\n",
    "                \"details\": []\n",
    "            }\n",
    "        ],\n",
    "        \"isComponent\": True\n",
    "    },\n",
    "    \"government_company\": {\n",
    "        \"subject\": \"\",\n",
    "        \"interestedParty\": \"\",\n",
    "        \"interests\": [{\n",
    "            \"type\": \"rightsToProfitOrIncome\",\n",
    "            \"directOrIndirect\": \"direct\",\n",
    "            \"beneficialOwnershipOrControl\": False,\n",
    "            \"details\": []\n",
    "        }],\n",
    "        \"isComponent\": True\n",
    "    },\n",
    "    \"company_project\": {\n",
    "        \"subject\": \"\",\n",
    "        \"interestedParty\": \"\",\n",
    "        \"interests\": [{\n",
    "            \"type\": \"rightsGrantedByContract\",\n",
    "            \"directOrIndirect\": \"direct\",\n",
    "            \"beneficialOwnershipOrControl\": False,\n",
    "            \"details\": []\n",
    "        }],\n",
    "        \"isComponent\": True\n",
    "    },\n",
    "    \"government_project\": {\n",
    "        \"subject\": \"\",\n",
    "        \"interestedParty\": \"\",\n",
    "        \"interests\": [{\n",
    "            \"type\": \"controlByLegalFramework\",\n",
    "            \"directOrIndirect\": \"indirect\",\n",
    "            \"beneficialOwnershipOrControl\": False,\n",
    "        }],\n",
    "        \"isComponent\": False,\n",
    "        \"componentRecords\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "relationship_dicts = {\n",
    "    \"country_government\": {},\n",
    "    \"government_soe\": {},\n",
    "    \"government_company\": {},\n",
    "    \"company_project\": {},\n",
    "    \"government_project\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. we define a function to map and process df_part5 to generate the relationship JSONs. They are then stored within their matching inner dictionary inside of relationship_dicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_government: 31826 items\n",
      "government_soe: 2611 items\n",
      "government_company: 28889 items\n",
      "company_project: 12320 items\n",
      "government_project: 11832 items\n"
     ]
    }
   ],
   "source": [
    "def populate_relationships(df, relationship_type, schema, subject_col, interested_party_col, start_date_col):\n",
    "    relationship_dicts[relationship_type] = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        if pd.notna(row[subject_col]) and pd.notna(row[interested_party_col]):\n",
    "            relationship_json = copy.deepcopy(schema)\n",
    "            relationship_json[\"subject\"] = row[subject_col]\n",
    "            relationship_json[\"interestedParty\"] = row[interested_party_col]\n",
    "            \n",
    "            for interest in relationship_json[\"interests\"]:\n",
    "                interest[\"startDate\"] = row[start_date_col]\n",
    "                if \"details\" in interest:\n",
    "                    detail = {\n",
    "                        \"revenue_stream_name\": row[\"revenue_stream_name\"],\n",
    "                        \"revenue_value\": row[\"revenue_value\"],\n",
    "                        \"reporting_currency\": row[\"reporting_currency\"]\n",
    "                    }\n",
    "                    if pd.notna(row[\"in_kind_volume\"]):\n",
    "                        detail[\"in_kind_volume\"] = row[\"in_kind_volume\"]\n",
    "                    if pd.notna(row[\"in_kind_unit\"]):\n",
    "                        detail[\"in_kind_unit\"] = row[\"in_kind_unit\"]\n",
    "                    interest[\"details\"].append(detail)\n",
    "            \n",
    "            relationship_dicts[relationship_type][(index, row['eiti_id_declaration'])] = json.dumps(relationship_json, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Pre-filter DataFrame to avoid repetitive filtering\n",
    "df_soes = df_part5[df_part5['company_type'] == \"State-owned enterprises & public corporations\"]\n",
    "df_private = df_part5[df_part5['company_type'] == \"Private\"]\n",
    "\n",
    "# Populate relationships\n",
    "populate_relationships(df_part5, \"country_government\", relationship_schemas[\"country_government\"], \"government_entity\", \"iso_alpha2_code\", \"start_date\")\n",
    "populate_relationships(df_soes, \"government_soe\", relationship_schemas[\"government_soe\"], \"company_name\", \"government_entity\", \"start_date\")\n",
    "populate_relationships(df_private, \"government_company\", relationship_schemas[\"government_company\"], \"company_name\",\"government_entity\", \"start_date\")\n",
    "populate_relationships(df_part5, \"company_project\", relationship_schemas[\"company_project\"], \"project_name\", \"company_name\", \"start_date\")\n",
    "populate_relationships(df_part5, \"government_project\", relationship_schemas[\"government_project\"], \"project_name\", \"government_entity\", \"start_date\")\n",
    "\n",
    "# Print the number of items in each dictionary\n",
    "for relationship_type, relationships in relationship_dicts.items():\n",
    "    print(f\"{relationship_type}: {len(relationships)} items\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. We verify the output by printing 1 random entry from each inner dictionary of relationship_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples from country_government:\n",
      "(5985, 'e821dd0c-7660-3334-a55a-732ab12351d7'): {\n",
      "  \"subject\": \"ALBANIAN CUSTOMS ADMINISTRATE\",\n",
      "  \"interestedParty\": \"AL\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"controlByLegalFramework\",\n",
      "      \"directOrIndirect\": \"direct\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"startDate\": \"2018-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": false\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "Samples from government_soe:\n",
      "(32384, 'fef32215-a021-3118-bdc3-a44079a72bdd'): {\n",
      "  \"subject\": \"UKRNAFTA PJSC\",\n",
      "  \"interestedParty\": \"STATE TAX SERVICE OF UKRAINE\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"controlByLegalFramework\",\n",
      "      \"directOrIndirect\": \"direct\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"startDate\": \"2020-01-01\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"rightsToProfitOrIncome\",\n",
      "      \"directOrIndirect\": \"direct\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"details\": [\n",
      "        {\n",
      "          \"revenue_stream_name\": \"Production royalty\",\n",
      "          \"revenue_value\": NaN,\n",
      "          \"reporting_currency\": \"UAH\"\n",
      "        }\n",
      "      ],\n",
      "      \"startDate\": \"2020-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": true\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "Samples from government_company:\n",
      "(22172, 'e5e7c542-e52b-3dda-adad-8cd101ea7fdb'): {\n",
      "  \"subject\": \"ICVL ZAMBEZE LDA\",\n",
      "  \"interestedParty\": \"TAX REVENUE AUTHORITY\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"rightsToProfitOrIncome\",\n",
      "      \"directOrIndirect\": \"direct\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"details\": [\n",
      "        {\n",
      "          \"revenue_stream_name\": \"IRPS\",\n",
      "          \"revenue_value\": 14687057.0,\n",
      "          \"reporting_currency\": \"MZN\",\n",
      "          \"in_kind_unit\": \"n/v\"\n",
      "        }\n",
      "      ],\n",
      "      \"startDate\": \"2019-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": true\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "Samples from company_project:\n",
      "(9918, 'ffba0b4e-e211-3ba8-9df9-fc6f919281a4'): {\n",
      "  \"subject\": \"OIL PIPELINE - CLAIR PIPELINE\",\n",
      "  \"interestedParty\": \"BP UK GROUP\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"rightsGrantedByContract\",\n",
      "      \"directOrIndirect\": \"direct\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"details\": [\n",
      "        {\n",
      "          \"revenue_stream_name\": \"Payments to Crown Estate Scotland O&G\",\n",
      "          \"revenue_value\": 124671.0,\n",
      "          \"reporting_currency\": \"GBP\",\n",
      "          \"in_kind_unit\": \"n/v\"\n",
      "        }\n",
      "      ],\n",
      "      \"startDate\": \"2018-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": true\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "Samples from government_project:\n",
      "(27092, 'e7c2170f-97e5-3330-9cdf-3e27e3dc7ca3'): {\n",
      "  \"subject\": \"n/v\",\n",
      "  \"interestedParty\": \"SOCIÉTÉ DES HYDROCARBURES DU TCHAD (SHT)\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"controlByLegalFramework\",\n",
      "      \"directOrIndirect\": \"indirect\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"startDate\": \"2018-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": false,\n",
      "  \"componentRecords\": []\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to print random samples from each relationship dictionary\n",
    "def relationship_sample(relationship_dicts, num_keys=1):\n",
    "    for relationship_type, relationships in relationship_dicts.items():\n",
    "        print(f\"Samples from {relationship_type}:\")\n",
    "        print_random_keys(relationships, num_keys=num_keys)\n",
    "\n",
    "relationship_sample(relationship_dicts, num_keys=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. We combine the relationship dictionaries into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relationship entities: 87478\n"
     ]
    }
   ],
   "source": [
    "relationship_dict = {}\n",
    "index = 0\n",
    "\n",
    "for relationship_type, relationships in relationship_dicts.items():\n",
    "    for key, value in relationships.items():\n",
    "        # Create a new global key using the global index\n",
    "        new_key = (index, eiti_id_declaration)\n",
    "        relationship_dict[new_key] = value\n",
    "        index += 1\n",
    "\n",
    "# Print the total number of relationship entities\n",
    "print(f\"Number of relationship entities: {len(relationship_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5. We verify the output by printing 2 random statement_dict entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77219, '5abb2996-ea0c-36b0-a728-8e9de6fe4f97'): {\n",
      "  \"subject\": \"LIANZI - NEMBA\",\n",
      "  \"interestedParty\": \"DIRECTION GÉNÉRALE DES IMPÔTS ET DES DOMAINES (DGID)\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"controlByLegalFramework\",\n",
      "      \"directOrIndirect\": \"indirect\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"startDate\": \"2017-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": false,\n",
      "  \"componentRecords\": []\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "(84658, '5abb2996-ea0c-36b0-a728-8e9de6fe4f97'): {\n",
      "  \"subject\": \"TUBAY NICKEL-COBALT PROJECT\",\n",
      "  \"interestedParty\": \"BUREAU OF INTERNAL REVENUE (BIR)\",\n",
      "  \"interests\": [\n",
      "    {\n",
      "      \"type\": \"controlByLegalFramework\",\n",
      "      \"directOrIndirect\": \"indirect\",\n",
      "      \"beneficialOwnershipOrControl\": false,\n",
      "      \"startDate\": \"2018-01-01\"\n",
      "    }\n",
      "  ],\n",
      "  \"isComponent\": false,\n",
      "  \"componentRecords\": []\n",
      "}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_random_keys(relationship_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Final matching\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Matching entities with statements\n",
    "2. Matching relationships with statements\n",
    "3. Grouping all statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Matching entities with statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combined entries: 0\n"
     ]
    }
   ],
   "source": [
    "entity_statement_dict = {}\n",
    "\n",
    "for (index, eiti_id_declaration) in entity_dict.keys():\n",
    "    if eiti_id_declaration in statement_dict:\n",
    "        statement = json.loads(statement_dict[eiti_id_declaration])\n",
    "        entity = json.loads(entity_dict[(index, eiti_id_declaration)])\n",
    "        statement[\"recordDetails\"] = entity\n",
    "\n",
    "        # Set recordId and recordType in statement_dict\n",
    "        statement[\"recordId\"] = entity[\"identifiers\"][0][\"id\"]\n",
    "        statement[\"recordType\"] = 'entity'\n",
    "        \n",
    "        entity_statement_dict[index] = json.dumps(statement, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Print the length of the combined dictionary\n",
    "print(f\"Number of combined entries: {len(entity_statement_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming relationship_dicts and statement_dict are already defined\n",
    "\n",
    "combined_relationships_dict = {}\n",
    "\n",
    "for relationship_type, relationships in relationship_dicts.items():\n",
    "    for (index, eiti_id_declaration), relationship in relationships.items():\n",
    "        if eiti_id_declaration in statement_dict:\n",
    "            statement = json.loads(statement_dict[eiti_id_declaration])\n",
    "            relationship_data = json.loads(relationship)\n",
    "            \n",
    "            # Add relationship data to the statement\n",
    "            statement[\"recordDetails\"] = relationship_data\n",
    "            \n",
    "            # Set recordId and recordType in statement_dict\n",
    "            statement[\"recordId\"] = generate_uuid3(relationship_data[\"subject\"], relationship_data[\"interestedParty\"])  # Updated line\n",
    "            statement[\"recordType\"] = 'relationship'\n",
    "            \n",
    "            combined_relationships_dict[(relationship_type, index)] = json.dumps(statement, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Print the length of the combined dictionary\n",
    "print(f\"Number of combined relationship entries: {len(combined_relationships_dict)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample a random item from a flat dictionary\n",
    "def sample_relationships(flat_dict):\n",
    "    random_key = random.choice(list(flat_dict.keys()))\n",
    "    return {random_key: flat_dict[random_key]}\n",
    "\n",
    "# Sample a random item from the combined relationship dictionary\n",
    "sampled_relationship = sample_relationships(combined_relationships_dict)\n",
    "\n",
    "# Separator for clarity\n",
    "separator = \"-\" * 40\n",
    "\n",
    "# Print the sampled relationships\n",
    "for (relationship_type, index), sample in sampled_relationship.items():\n",
    "    print(f\"Sample from {relationship_type} (index {index}):\")\n",
    "    print(f\"Value: {sample}\\n{separator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unified dictionary\n",
    "unified_dict = {}\n",
    "\n",
    "# Update statementId and add to unified dictionary using original index\n",
    "for key, value in combined_dict.items():\n",
    "    statement = json.loads(value)\n",
    "    statement[\"statementId\"] = generate_uuid4()\n",
    "    unified_dict[key] = statement\n",
    "\n",
    "# Prepare to sort relationships\n",
    "relationships_list = []\n",
    "for relationship_type, relationships in relationship_dicts.items():\n",
    "    for (index, eiti_id_declaration), relationship in relationships.items():\n",
    "        relationship_data = json.loads(relationship)\n",
    "        statement = json.loads(statement_dict[eiti_id_declaration])\n",
    "        statement[\"recordDetails\"] = relationship_data\n",
    "        statement[\"statementId\"] = generate_uuid4()\n",
    "        statement[\"recordType\"] = 'relationship'\n",
    "        relationships_list.append((relationship_type, statement, relationship_data[\"interests\"][0][\"startDate\"], eiti_id_declaration, index))\n",
    "\n",
    "# Sort relationships by start_date and eiti_id_relationship\n",
    "relationships_list.sort(key=lambda x: (x[2], x[3]))\n",
    "\n",
    "# Create grouped relationships dictionary\n",
    "grouped_relationships = {}\n",
    "for relationship_type, statement, _, eiti_id_declaration, index in relationships_list:\n",
    "    if eiti_id_declaration not in grouped_relationships:\n",
    "        grouped_relationships[eiti_id_declaration] = []\n",
    "    grouped_relationships[eiti_id_declaration].append((relationship_type, statement, index))\n",
    "\n",
    "# Order and update componentRecords for government_project items\n",
    "for eiti_id_declaration, relations in grouped_relationships.items():\n",
    "    sorted_relations = sorted(relations, key=lambda x: ['country_government', 'government_company', 'government_soe', 'company_project', 'government_project'].index(x[0]))\n",
    "    for relationship_type, statement, index in sorted_relations:\n",
    "        unified_dict[index] = statement\n",
    "        if relationship_type == 'government_project':\n",
    "            component_records = [s for t, s, idx in sorted_relations if t in ['government_company', 'government_soe', 'company_project']]\n",
    "            if component_records:\n",
    "                # this needs fixing, it's not clear how it's filling this value\n",
    "                unified_dict[index][\"recordDetails\"][\"componentRecords\"] = [r[\"recordDetails\"] for r in component_records] \n",
    "\n",
    "\n",
    "# Print the number of combined entries\n",
    "print(f\"Number of combined entries: {len(unified_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample a random item from each type\n",
    "def sample_random_items(unified_dict):\n",
    "    samples = {\n",
    "        \"companies\": [],\n",
    "        \"soe\": [],\n",
    "        \"gov_agency\": [],\n",
    "        \"relationship\": []\n",
    "    }\n",
    "\n",
    "    for key, value in unified_dict.items():\n",
    "        record_details = value.get(\"recordDetails\", {})\n",
    "        entity_type = record_details.get(\"entityType\", {}).get(\"type\", \"\")\n",
    "        record_type = value.get(\"recordType\", \"\")\n",
    "\n",
    "        if entity_type == \"registeredEntity\" and record_type == \"entity\":\n",
    "            samples[\"companies\"].append((key, value))\n",
    "        elif entity_type == \"stateOwnedEntity\" and record_type == \"entity\":\n",
    "            samples[\"soe\"].append((key, value))\n",
    "        elif entity_type == \"stateBody\" and record_type == \"entity\":\n",
    "            samples[\"gov_agency\"].append((key, value))\n",
    "        elif record_type == \"relationship\":\n",
    "            samples[\"relationship\"].append((key, value))\n",
    "\n",
    "    return {type_: random.choice(items) if items else None for type_, items in samples.items()}\n",
    "\n",
    "# Get random samples\n",
    "random_samples = sample_random_items(unified_dict)\n",
    "\n",
    "# Print the samples with separators\n",
    "for entity_type, sample in random_samples.items():\n",
    "    if sample:\n",
    "        key, value = sample\n",
    "        print(f\"Sample from {entity_type}:\")\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"Value: {json.dumps(value, indent=2, ensure_ascii=False)}\")\n",
    "        print(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the relationship dictionaries ensuring unique (index, eiti_id_declaration) keys\n",
    "merged_relationships = {}\n",
    "\n",
    "for relationship_type, relationships in relationship_dicts.items():\n",
    "    for key, relationship_json in relationships.items():\n",
    "        index, eiti_id_declaration = key\n",
    "        if eiti_id_declaration not in merged_relationships:\n",
    "            merged_relationships[eiti_id_declaration] = []\n",
    "        merged_relationships[eiti_id_declaration].append((index, relationship_json))\n",
    "\n",
    "\n",
    "print(f\"The merged dictionary has {len(merged_relationships)} items\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the unified dictionary\n",
    "unified_dict = {}\n",
    "\n",
    "for eiti_id_declaration, relationship_entries in merged_relationships.items():\n",
    "    if eiti_id_declaration in statement_dict:\n",
    "        statement_json = json.loads(statement_dict[eiti_id_declaration])\n",
    "        for index, relationship_json in relationship_entries:\n",
    "            statement_copy = copy.deepcopy(statement_json)\n",
    "            statement_copy['recordDetails'] = json.loads(relationship_json)\n",
    "            unified_key = (index, eiti_id_declaration)\n",
    "            unified_dict[unified_key] = json.dumps(statement_copy, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Print the number of items in the unified dictionary\n",
    "print(f\"The unified dictionary has {len(unified_dict)} items\")\n",
    "\n",
    "# Print a sample of 2 random items from the unified dictionary\n",
    "separator = \"-\" * 40\n",
    "random_keys = random.sample(list(unified_dict.keys()), 2)\n",
    "\n",
    "for random_key in random_keys:\n",
    "    print(f\"{random_key}: {unified_dict[random_key]}\\n{separator}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ensure proper UTF-8 encoding\n",
    "def ensure_utf8(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.encode('utf-8', errors='replace').decode('utf-8')\n",
    "    return value\n",
    "\n",
    "# Select a random eiti_id_declaration from unified_dict\n",
    "random_declaration = random.choice([value['declaration'] for value in unified_dict.values()])\n",
    "\n",
    "# Filter the unified_dict for entries matching the selected eiti_id_declaration\n",
    "filtered_entries = [ensure_utf8(value) for value in unified_dict.values() if value.get('declaration') == random_declaration]\n",
    "\n",
    "# Print the number of filtered entries\n",
    "print(f\"Number of entries for eiti_id_declaration '{random_declaration}': {len(filtered_entries)}\")\n",
    "\n",
    "# Output the filtered entries as a single JSON array\n",
    "output_file = f\"filtered_entries_{random_declaration}.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_entries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Print a message confirming the file creation\n",
    "print(f\"Filtered entries saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Filter unified_dict to get only government_project items\n",
    "government_project_items = {key: value for key, value in unified_dict.items() if value[\"recordType\"] == \"relationship\" and value[\"recordDetails\"][\"isComponent\"] == False}\n",
    "\n",
    "# Ensure there are government_project items\n",
    "if government_project_items:\n",
    "    # Select a random item\n",
    "    random_key = random.choice(list(government_project_items.keys()))\n",
    "    random_item = government_project_items[random_key]\n",
    "\n",
    "    # Print the random government_project item\n",
    "    print(f\"Random government_project item (Key: {random_key}):\")\n",
    "    print(json.dumps(random_item, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"No government_project items found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
